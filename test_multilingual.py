#!/usr/bin/env python3
"""
Multi-Language Support Testing Script
Test chat and document uploads in various languages
"""

import sys
import os
sys.path.append('backend')

from backend.language_support import MultiLanguageSupport, MultilingualContentFilter

def test_language_detection():
    """Test language detection for various languages"""
    print("ğŸŒ Testing Language Detection")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    test_messages = {
        'en': "Hello, how are you today?",
        'hi': "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?", 
        'ja': "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ",
        'zh': "ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ",
        'ko': "ì•ˆë…•í•˜ì„¸ìš”, ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
        'ar': "Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ",
        'es': "Hola, Â¿cÃ³mo estÃ¡s?",
        'fr': "Bonjour, comment allez-vous?",
        'de': "Hallo, wie geht es dir?",
        'ru': "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?",
        'pt': "OlÃ¡, como vocÃª estÃ¡?"
    }
    
    correct_detections = 0
    total_tests = len(test_messages)
    
    for expected_lang, message in test_messages.items():
        detected_lang, confidence = lang_support.detect_language(message)
        
        # Some tolerance for similar languages
        is_correct = (detected_lang == expected_lang or 
                     (expected_lang == 'zh' and detected_lang in ['zh', 'zh-cn', 'zh-tw']))
        
        if is_correct:
            correct_detections += 1
            status = "âœ…"
        else:
            status = "âŒ"
        
        lang_name = lang_support.supported_languages.get(detected_lang, {}).get('name', detected_lang)
        
        print(f"{status} Expected: {expected_lang} | Detected: {detected_lang} ({lang_name}) | Confidence: {confidence:.2f}")
        print(f"   Message: {message}")
        print()
    
    accuracy = (correct_detections / total_tests) * 100
    print(f"ğŸ“Š Detection Accuracy: {correct_detections}/{total_tests} ({accuracy:.1f}%)")
    print()

def test_content_filtering():
    """Test content filtering in multiple languages"""
    print("ğŸ›¡ï¸ Testing Multi-Language Content Filtering")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    # Safe content in various languages
    safe_messages = {
        'en': "What is artificial intelligence?",
        'hi': "à¤•à¥ƒà¤¤à¥à¤°à¤¿à¤® à¤¬à¥à¤¦à¥à¤§à¤¿à¤®à¤¤à¥à¤¤à¤¾ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
        'ja': "äººå·¥çŸ¥èƒ½ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        'zh': "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        'es': "Â¿QuÃ© es la inteligencia artificial?",
        'fr': "Qu'est-ce que l'intelligence artificielle?"
    }
    
    # Inappropriate content in various languages
    unsafe_messages = {
        'en': "How to make bombs",
        'hi': "à¤¬à¤® à¤•à¥ˆà¤¸à¥‡ à¤¬à¤¨à¤¾à¤à¤‚",
        'ja': "çˆ†å¼¾ã®ä½œã‚Šæ–¹",
        'zh': "å¦‚ä½•åˆ¶é€ ç‚¸å¼¹",
        'es': "CÃ³mo hacer bombas",
        'fr': "Comment faire des bombes"
    }
    
    print("âœ… Testing Safe Content:")
    for lang, message in safe_messages.items():
        result = lang_support.process_multilingual_chat(message)
        status = "âœ… SAFE" if result['is_safe'] else "âŒ BLOCKED"
        print(f"   {status} [{lang}]: {message}")
    
    print("\nâŒ Testing Unsafe Content:")
    for lang, message in unsafe_messages.items():
        result = lang_support.process_multilingual_chat(message)
        status = "âœ… BLOCKED" if not result['is_safe'] else "âŒ ALLOWED"
        print(f"   {status} [{lang}]: {message}")
        if not result['is_safe']:
            print(f"      Reason: {result['safety_reason']}")
    
    print()

def test_document_processing():
    """Test document language processing"""
    print("ğŸ“„ Testing Document Language Processing")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    # Sample documents in different languages
    documents = {
        'english_doc.txt': "This is a technical documentation about artificial intelligence and machine learning algorithms.",
        'spanish_doc.txt': "Este es un documento tÃ©cnico sobre inteligencia artificial y algoritmos de aprendizaje automÃ¡tico.",
        'french_doc.txt': "Ceci est une documentation technique sur l'intelligence artificielle et les algorithmes d'apprentissage automatique.",
        'german_doc.txt': "Dies ist eine technische Dokumentation Ã¼ber kÃ¼nstliche Intelligenz und maschinelle Lernalgorithmen.",
        'chinese_doc.txt': "è¿™æ˜¯å…³äºäººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ç®—æ³•çš„æŠ€æœ¯æ–‡æ¡£ã€‚",
        'japanese_doc.txt': "ã“ã‚Œã¯äººå·¥çŸ¥èƒ½ã¨æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹æŠ€è¡“æ–‡æ›¸ã§ã™ã€‚"
    }
    
    for filename, content in documents.items():
        doc_analysis = lang_support.validate_document_language(content, filename)
        
        detected_lang = doc_analysis['detected_language']
        lang_name = doc_analysis['language_info']['name']
        is_safe = doc_analysis['is_safe']
        needs_translation = doc_analysis['needs_translation']
        
        status = "âœ…" if is_safe else "âŒ"
        translate_info = "ğŸ”„ Will translate" if needs_translation else "ğŸ“ English ready"
        
        print(f"{status} {filename}")
        print(f"   Language: {lang_name} ({detected_lang})")
        print(f"   Confidence: {doc_analysis['confidence']:.2f}")
        print(f"   Safe: {'Yes' if is_safe else 'No'}")
        print(f"   Translation: {translate_info}")
        print(f"   Size: {doc_analysis['content_length']} â†’ {doc_analysis['english_length']} chars")
        print()

def test_greeting_detection():
    """Test greeting detection in multiple languages"""
    print("ğŸ‘‹ Testing Greeting Detection")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    greetings = {
        'en': ["Hello", "Hi there", "Good morning"],
        'hi': ["à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤¹à¥ˆà¤²à¥‹", "à¤¸à¥à¤ªà¥à¤°à¤­à¤¾à¤¤"],
        'ja': ["ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯"],
        'zh': ["ä½ å¥½", "æ—©ä¸Šå¥½", "æ™šä¸Šå¥½"],
        'es': ["Hola", "Buenos dÃ­as", "Buenas tardes"],
        'fr': ["Bonjour", "Bonsoir", "Salut"]
    }
    
    for lang, lang_greetings in greetings.items():
        print(f"ğŸŒ {lang.upper()} Greetings:")
        for greeting in lang_greetings:
            result = lang_support.process_multilingual_chat(greeting)
            detected = "âœ… Detected" if result['is_greeting'] else "âŒ Missed"
            print(f"   {detected}: {greeting}")
        print()

def test_mixed_language():
    """Test mixed language content"""
    print("ğŸŒ Testing Mixed Language Content")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    mixed_messages = [
        "Hello à¤¨à¤®à¤¸à¥à¤¤à¥‡ ã“ã‚“ã«ã¡ã¯",  # English + Hindi + Japanese
        "Thank you merci è°¢è°¢",      # English + French + Chinese
        "Programming ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° coding",  # English + Japanese + English
        "AIäººå·¥æ™ºèƒ½ machine learning",  # Mixed Chinese-English tech terms
    ]
    
    for message in mixed_messages:
        result = lang_support.process_multilingual_chat(message)
        
        print(f"Message: {message}")
        print(f"Primary Language: {result['language_info']['name']} ({result['detected_language']})")
        print(f"Mixed Script: {'Yes' if result['is_mixed_script'] else 'No'}")
        print(f"Confidence: {result['confidence']:.2f}")
        print()

def test_language_statistics():
    """Test detailed language statistics"""
    print("ğŸ“Š Testing Language Statistics")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    sample_text = "Hello world! This is a test message with some English content. ä½ å¥½ä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ã€‚"
    
    stats = lang_support.get_language_statistics(sample_text)
    
    print(f"Text: {sample_text}")
    print(f"Primary Language: {stats['primary_language']}")
    print(f"Primary Confidence: {stats['primary_confidence']:.3f}")
    print(f"Character Count: {stats['character_count']}")
    print(f"Word Count: {stats['word_count']}")
    print(f"Is Multilingual: {stats['is_multilingual']}")
    
    print("\nAll Detected Languages:")
    for lang_info in stats.get('all_detected_languages', []):
        print(f"   {lang_info['name']} ({lang_info['language']}): {lang_info['confidence']:.3f}")
    
    print(f"\nUnique Scripts: {stats.get('unique_scripts', [])}")
    print()

def test_supported_languages():
    """Test supported languages information"""
    print("ğŸ—ºï¸ Testing Supported Languages")
    print("=" * 50)
    
    lang_support = MultiLanguageSupport()
    
    lang_info = lang_support.get_supported_languages_info()
    
    print(f"Total Supported Languages: {lang_info['total_languages']}")
    print()
    
    print("ğŸŒ All Supported Languages:")
    for code, info in lang_info['languages'].items():
        rtl_indicator = " (RTL)" if info.get('rtl', False) else ""
        translate_indicator = " ğŸ”„" if info.get('auto_translate', False) else ""
        print(f"   {code}: {info['native_name']} ({info['name']}){rtl_indicator}{translate_indicator}")
    
    print(f"\nâ¡ï¸ RTL Languages: {', '.join(lang_info['rtl_languages'])}")
    print(f"ğŸ”„ Auto-Translate Languages: {len(lang_info['auto_translate_languages'])} languages")
    print()

def main():
    """Run all multi-language tests"""
    print("ğŸ§ª AI ChatBot Multi-Language Testing Suite")
    print("ğŸŒ Testing support for Hindi, Japanese, Chinese, and more!")
    print("=" * 60)
    print()
    
    try:
        test_language_detection()
        test_content_filtering()
        test_document_processing() 
        test_greeting_detection()
        test_mixed_language()
        test_language_statistics()
        test_supported_languages()
        
        print("ğŸ‰ Multi-Language Testing Complete!")
        print("\nğŸ’¡ Your ChatBot Now Supports:")
        print("   âœ… 12+ languages with automatic detection")
        print("   âœ… Content filtering in native languages")  
        print("   âœ… Document translation for knowledge base")
        print("   âœ… Responses in user's original language")
        print("   âœ… Mixed-language content handling")
        print("   âœ… RTL (Right-to-Left) language support")
        
        print("\nğŸš€ Ready for Global Deployment!")
        
    except ImportError as e:
        print(f"âŒ Import Error: {e}")
        print("Install missing dependencies:")
        print("pip install langdetect")
        print("pip install openai")
        
    except Exception as e:
        print(f"âŒ Test Error: {e}")
        print("Check your language support implementation")

if __name__ == "__main__":
    main() 